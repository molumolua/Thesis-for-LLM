# Abstract
如果我们利用一些被最终的verifyer认为是不正确的响应，其中的一些问题也可以解决。

这些负面反应必须被构造成“我们通过训练可以适当的恢复负面反应中的每个中间步骤的效用或者优势”。

# Introduction
合成的数据，学习者自己产生的和来自更大模型的一样有效。来自类似模型的响应比来自更有能力的模型的响应“更容易拟合”，从而在微调期间减少记忆。

如果正响应中包含不正确/不相关的中间步骤，往往会激励对虚假相关性的过拟合，从而导致反向效果。



